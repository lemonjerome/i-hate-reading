version: "3.9"

services:
  # NOTE: Run Ollama NATIVELY on macOS for Metal GPU acceleration.
  # Start it before docker-compose: `ollama serve`
  # Docker cannot access Apple Silicon GPU â€” running Ollama in Docker
  # forces CPU-only mode (0/37 layers offloaded to GPU).

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "timeout 10s bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s

  notebook-agent:
    build: 
      context: ./agent
      dockerfile: Dockerfile
    container_name: notebook-agent
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - OLLAMA_MODEL=qwen3:8b
      - QDRANT_HOST=http://qdrant:6333
      - RERANK_MODEL=BAAI/bge-reranker-base
      - ENABLE_RERANK=1
      - MAX_CONTEXT_CHUNKS=8
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      qdrant:
        condition: service_healthy
    restart: unless-stopped

networks:
  default:
    driver: bridge

volumes:
  qdrant_data: